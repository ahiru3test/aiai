{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175897572515981 0.7359028880290998\n",
      "0.7190252930186809 0.7295535344941491\n",
      "0.8456207631185566 0.8372526287986777\n",
      "0.8565689444345094 0.8425282632102126\n",
      "0.8643834988984441 0.8678022326740733\n",
      "0.8668534967796697 0.8739347357775972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7885767074746559"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "class SklModelResult():\n",
    "    def __init__(self, data=None):\n",
    "        self.x_train = data.get('x_train') if data else None\n",
    "        self.x_val = data.get('x_val') if data else None\n",
    "        self.y_train = data.get('y_train') if data else None\n",
    "        self.y_val = data.get('y_val') if data else None\n",
    "        self.sc_x_train = data.get('sc_x_train') if data else None\n",
    "        self.sc_x_val = data.get('sc_x_val') if data else None\n",
    "        self.sc_y_train = data.get('sc_y_train') if data else None\n",
    "        self.sc_y_val = data.get('sc_y_val') if data else None\n",
    "        self.is_standardization = data.get(\n",
    "            'is_standardization') if data else None\n",
    "        self.sc_x_model = data.get('sc_x_model') if data else None\n",
    "        self.sc_y_model = data.get('sc_y_model') if data else None\n",
    "        self.model = data.get('model') if data else None\n",
    "        self.train_score = data.get('train_score') if data else None\n",
    "        self.val_score = data.get('val_score') if data else None\n",
    "\n",
    "\n",
    "\n",
    "class SklModel():\n",
    "    # dataframe = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "        self.columns = None\n",
    "        self.test_parameters = {}\n",
    "        self.model_parameters = {}\n",
    "        self.dataframe= None\n",
    "        # self.dataframe_org= None\n",
    "        self.filepath = None\n",
    "\n",
    "    #step1 csvファイルの読込\n",
    "    def set_filepath(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.dataframe = pd.read_csv(filepath) # CSV読込\n",
    "        # self.dataframe_org=self.dataframe.copy()\n",
    "        return self.dataframe\n",
    "\n",
    "    #step2 ダミー変数の設定\n",
    "    def get_dummy_columns(self, df:pd.DataFrame, columns:list, drop=0):\n",
    "        drop_flag = {0:False,1:True}\n",
    "        # print(drop_flag[drop])\n",
    "        for column in columns:\n",
    "            dummy = pd.get_dummies(\n",
    "                df[column], drop_first=drop_flag[drop], dtype=int)\n",
    "            df = pd.concat([df, dummy], axis=1)\n",
    "        df = df.drop(columns, axis=1)\n",
    "        return df\n",
    "\n",
    "    def set_test_parameters(self, parameters):\n",
    "        self.test_parameters = parameters\n",
    "\n",
    "    #step3\n",
    "    def split(self,*parrays):\n",
    "        # データを分割する\n",
    "        return train_test_split(\n",
    "            *parrays, **self.test_parameters)\n",
    "\n",
    "    def set_target(self, target_column):\n",
    "        self.target_column = target_column\n",
    "\n",
    "        # 特徴量と正解ラベルを分割する\n",
    "        if self.columns is None:\n",
    "            columns = self.dataframe.drop(\n",
    "                self.target_column, axis=1).columns.tolist()\n",
    "            self.set_columns(columns)\n",
    "        \n",
    "        return self.target_column\n",
    "\n",
    "    def get_target(self):\n",
    "        return self.target_column\n",
    "\n",
    "    def set_columns(self, columns):\n",
    "        self.columns = columns\n",
    "        return self.columns\n",
    "        # return cls.columns := columns\n",
    "\n",
    "    def get_columns(self):\n",
    "        return self.columns\n",
    "    \n",
    "    def fillna_meaning(self, df) -> pd.DataFrame:\n",
    "        return df.fillna(df.mean())\n",
    "    \n",
    "    def ss_transform(self, df, model=None):\n",
    "        if (model is None):\n",
    "            sc_model_x = StandardScaler() #訓練データxの標準化モデル\n",
    "            sc_model_x.fit(df)\n",
    "            sc_x = sc_model_x.transform(df) #標準化されたxのdfデータ\n",
    "            return sc_x, sc_model_x\n",
    "        else:\n",
    "            sc_model_x = model\n",
    "            sc_x = sc_model_x.transform(df) #標準化されたxのdfデータ\n",
    "            return sc_x\n",
    "\n",
    "    def set_model_parameters(self, parameters):\n",
    "        self.model_parameters = parameters\n",
    "\n",
    "    def get_model_parameters(self, parameters):\n",
    "        return self.model_parameters\n",
    "\n",
    "    def init_model(self,model_name=\"\"):\n",
    "        if(model_name==\"DecisionTreeClassifier\"):\n",
    "            return DecisionTreeClassifier(**self.model_parameters)\n",
    "        elif(model_name==\"LinearRegression\"):\n",
    "            return LinearRegression(**self.model_parameters)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def learn(self, x, y, is_standardization=False, x_model=None, y_model=None):\n",
    "        ###テスト分割\n",
    "        x_train, x_val, y_train, y_val = train_test_split(\n",
    "            x, y, **self.test_parameters)\n",
    "        ### 訓練データを標準化\n",
    "        if(x_model is None or y_model is None):\n",
    "            sc_x_model = StandardScaler()\n",
    "            sc_y_model = StandardScaler()\n",
    "            sc_x_model.fit(x_train)\n",
    "            sc_x_train = sc_x_model.transform(x_train)\n",
    "            sc_y_model.fit(y_train)\n",
    "            sc_y_train = sc_y_model.transform(y_train)\n",
    "        else:\n",
    "            sc_x_train = x_train\n",
    "            sc_y_train = y_train\n",
    "        ### 学習\n",
    "        model = LinearRegression()\n",
    "        model.fit(sc_x_train, sc_y_train)\n",
    "        ### 検証データを標準化\n",
    "        sc_x_val = sc_x_model.transform(x_val)\n",
    "        sc_y_val = sc_y_model.transform(y_val)\n",
    "        ### 訓練データと検証データの決定係数計算\n",
    "        train_score = model.score(sc_x_train, sc_y_train)\n",
    "        val_score = model.score(sc_x_val, sc_y_val)\n",
    "\n",
    "        ### 戻り値\n",
    "        ret = {\n",
    "            'x_train': x_train,\n",
    "            'x_val': x_val,\n",
    "            'y_train': y_train,\n",
    "            'y_val': y_val,\n",
    "            'sc_x_train': sc_x_train,\n",
    "            'sc_x_val': sc_x_val,\n",
    "            'sc_y_train': sc_y_train,\n",
    "            'sc_y_val': sc_y_val,\n",
    "            'is_standardization': is_standardization,\n",
    "            'sc_x_model': sc_x_model,\n",
    "            'sc_y_model': sc_y_model,\n",
    "            'model': model,\n",
    "            'train_score': train_score,\n",
    "            'val_score': val_score,\n",
    "        }\n",
    "        return SklModelResult(ret)\n",
    "\n",
    "\n",
    "\n",
    "#8-1 CSVの読込\n",
    "import matplotlib.pyplot as plt #plot用の初期化\n",
    "%matplotlib inline\n",
    "sm=SklModel()\n",
    "df = sm.set_filepath(\"../datafiles/Boston.csv\")\n",
    "df.head(2)\n",
    "\n",
    "#8-3 CRIMEの調査\n",
    "df['CRIME'].value_counts()\n",
    "\n",
    "#8-4 ダミー変数設定(自動化候補)\n",
    "df2 = sm.get_dummy_columns(df, ['CRIME'], 1)\n",
    "df2\n",
    "\n",
    "#8-5 columnsもtargetも設定が無いので全てのcolumnsを分割\n",
    "sm.set_test_parameters({\"test_size\": 0.2, \"random_state\": 0})\n",
    "train_val,test = sm.split(df2)\n",
    "train_val,test\n",
    "\n",
    "#8-6 欠損値があるかどうかの確認\n",
    "train_val.isnull().sum()\n",
    "\n",
    "#8-7 欠損値を平均値で穴埋め（自動化候補）\n",
    "train_val2 = sm.fillna_meaning(train_val)\n",
    "train_val2\n",
    "\n",
    "# #8-8-2 外れ値の確認\n",
    "# fig = plt.figure(figsize=(8,10))\n",
    "# colname = train_val2.columns\n",
    "# colname\n",
    "# # for name in colname[:13]:\n",
    "# for n, col in enumerate(colname):\n",
    "#     train_val2.plot(\n",
    "#         ax=fig.add_subplot(5,3,n+1), kind='scatter', x= col, y='PRICE', s=3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "#8-9 外れ値が存在するインデックスの確認\n",
    "# RMの外れ値\n",
    "out_line1 = train_val2[(train_val2['RM'] < 6) &\n",
    "(train_val2['PRICE'] > 40)].index\n",
    "# PTRATIOの外れ値\n",
    "out_line2 = train_val2[(train_val2['PTRATIO'] > 18) &\n",
    "    (train_val2['PRICE'] > 40)].index\n",
    "# print(out_line1, out_line2)\n",
    "\n",
    "#8-10 外れ値の削除\n",
    "train_val3 = train_val2.drop([76], axis = 0)\n",
    "\n",
    "#8-11 予測に使用する特徴量の列以外を取り除く\n",
    "col = ['INDUS', 'NOX', 'RM', 'PTRATIO', 'LSTAT', 'PRICE']\n",
    "train_val4 = train_val3[col]\n",
    "train_val4.head(3)\n",
    "\n",
    "#8-12 各列同士の相関係数を調べる\n",
    "train_val4.corr()\n",
    "\n",
    "#8-13 PRICE列との相関係数を調べる\n",
    "train_cor = train_val4.corr()['PRICE']\n",
    "train_cor\n",
    "\n",
    "#8-16 各要素を絶対値に変換\n",
    "abs_cor = train_cor.map(abs)\n",
    "abs_cor\n",
    "\n",
    "#8-17 降順\n",
    "abs_cor.sort_values(ascending = False)\n",
    "\n",
    "#8-18 データ分割して訓練データと検証データに\n",
    "col =sm.set_columns(['RM', 'LSTAT', 'PTRATIO'])\n",
    "target = sm.set_target(['PRICE'])\n",
    "x = train_val4[col]\n",
    "t = train_val4[target]\n",
    "x_train, x_val, y_train, y_val = sm.split(x,t)\n",
    "x_train, x_val, y_train, y_val\n",
    "\n",
    "#8-19 データ標準化\n",
    "# sc_model_x = StandardScaler() #訓練データxの標準化モデル\n",
    "# sc_model_x.fit(x_train)\n",
    "\n",
    "# # 各列のデータを標準化してsc_xに代入\n",
    "# sc_x = sc_model_x.transform(x_train) #標準化されたxのdfデータ\n",
    "# sc_x # 表示\n",
    "sc_x, sc_model_x = sm.ss_transform(x_train)\n",
    "sc_x, sc_model_x\n",
    "\n",
    "#8-20 見やすくして平均値0（ほぼ0）を確認 = 標準化された\n",
    "# array 型だと見づらいのでデータフレームに変換\n",
    "tmp_df = pd.DataFrame(sc_x, columns = x_train.columns)\n",
    "# 平均値の計算\n",
    "tmp_df.mean()\n",
    "\n",
    "#8-21 標準偏差の計算\n",
    "tmp_df.std() # 標準偏差の計算\n",
    "\n",
    "#8-22 正解データを標準化\n",
    "sc_y,sc_model_y = sm.ss_transform(y_train)\n",
    "sc_y\n",
    "\n",
    "#8-23 標準化したデータで学習\n",
    "sm.set_model_parameters({\"fit_intercept\":True})\n",
    "model=sm.init_model(\"LinearRegression\")\n",
    "model.fit(sc_x,sc_y)\n",
    "\n",
    "#8-24 決定係数を求める\n",
    "model.score(x_val,y_val)\n",
    "\n",
    "# 8-25検証データを「訓練データのモデルで」標準化\n",
    "sc_x_val = sm.ss_transform(x_val,sc_model_x)\n",
    "sc_y_val = sm.ss_transform(y_val,sc_model_y)\n",
    "sc_x_val, sc_y_val\n",
    "model.score(sc_x_val, sc_y_val) # 標準化した検証データで決定係数を計算\n",
    "\n",
    "###8-27 learn関数\n",
    "x = train_val3.loc[ :, ['RM', 'LSTAT', 'PTRATIO']]\n",
    "t = train_val3[['PRICE']]\n",
    "ret = sm.learn(x, t, True)\n",
    "print(ret.train_score, ret.val_score)\n",
    "\n",
    "#8-29\n",
    "x = train_val3.loc[ :, ['RM', 'LSTAT', 'PTRATIO','INDUS']]\n",
    "t = train_val3[['PRICE']]\n",
    "ret = sm.learn(x, t, True)\n",
    "print(ret.train_score, ret.val_score)\n",
    "\n",
    "#8-30\n",
    "x['RM'] ** 2\n",
    "\n",
    "#8-31\n",
    "# RM2乗のシリーズを新しい列として追加\n",
    "x['RM2'] = x['RM'] ** 2\n",
    "# コード8-29で、INDUS列を追加したので削除\n",
    "x = x.drop('INDUS', axis = 1)\n",
    "x.head(2)\n",
    "\n",
    "#8-33\n",
    "ret = sm.learn(x, t, True)\n",
    "print(ret.train_score, ret.val_score)\n",
    "\n",
    "#8-34\n",
    "# LSTAT列の2乗を追加\n",
    "x['LSTAT2'] = x['LSTAT'] ** 2\n",
    "ret = sm.learn(x, t, True)\n",
    "print(ret.train_score, ret.val_score)\n",
    "\n",
    "# PTRATIO列の2乗を追加\n",
    "x['PTRATIO2'] = x['PTRATIO'] ** 2\n",
    "ret = sm.learn(x, t, True)\n",
    "print(ret.train_score, ret.val_score)\n",
    "\n",
    "#8-36\n",
    "x['RM * LSTAT'] = x['RM'] * x['LSTAT']\n",
    "x.head(2)\n",
    "\n",
    "#8-37\n",
    "ret = sm.learn(x, t, True)\n",
    "print(ret.train_score, ret.val_score)\n",
    "\n",
    "#    def learn(self, x, y, is_standardization=False, x_model=None, y_model=None):\n",
    "\n",
    "#8-38\n",
    "# 訓練データと検証データを合わせて再学習させるので\n",
    "# 再度、標準化する\n",
    "\n",
    "ret = sm.learn(x, t, True)\n",
    "\n",
    "#8-39\n",
    "test2 = test.fillna(train_val.mean()) # 欠損値を平均値で補完\n",
    "x_test = test2.loc[ :, ['RM','LSTAT', 'PTRATIO'] ]\n",
    "y_test = test2[['PRICE']]\n",
    "\n",
    "x_test['RM2'] = x_test['RM'] ** 2\n",
    "x_test['LSTAT2'] = x_test['LSTAT'] ** 2\n",
    "x_test['PTRATIO2'] = x_test['PTRATIO'] ** 2\n",
    "\n",
    "x_test['RM * LSTAT'] = x_test['RM'] * x_test['LSTAT']\n",
    "\n",
    "\n",
    "sc_x_test = ret.sc_x_model.transform(x_test)\n",
    "sc_y_test = ret.sc_y_model.transform(y_test)\n",
    "\n",
    "#8-40\n",
    "ret.model.score(sc_x_test, sc_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#8-38\n",
    "# 訓練データと検証データを合わせて再学習させるので\n",
    "# 再度、標準化する\n",
    "\n",
    "sc_x, sc_model_x2 = sm.ss_transform(x)\n",
    "sc_y, sc_model_y2 = sm.ss_transform(t)\n",
    "model=sm.init_model(\"LinearRegression\")\n",
    "model.fit(sc_x, sc_y)\n",
    "\n",
    "#8-39\n",
    "test2 = test.fillna(train_val.mean()) # 欠損値を平均値で補完\n",
    "x_test = test2.loc[ :, ['RM','LSTAT', 'PTRATIO'] ]\n",
    "y_test = test2[['PRICE']]\n",
    "\n",
    "x_test['RM2'] = x_test['RM'] ** 2\n",
    "x_test['LSTAT2'] = x_test['LSTAT'] ** 2\n",
    "x_test['PTRATIO2'] = x_test['PTRATIO'] ** 2\n",
    "\n",
    "x_test['RM * LSTAT'] = x_test['RM'] * x_test['LSTAT']\n",
    "\n",
    "\n",
    "\n",
    "sc_x_test = sm.ss_transform(x_test,sc_model_x2)\n",
    "sc_y_test = sm.ss_transform(y_test,sc_model_y2)\n",
    "\n",
    "# ret.sc_x_model, ret.sc_y_model, sc_x_test, sc_y_test\n",
    "\n",
    "#8-40\n",
    "model.score(sc_x_test, sc_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #8-41モデルの保存\n",
    "# import pickle\n",
    "# with open('boston.pkl',\"wb\") as f:\n",
    "#     pickle.dump(model,f) #モデルの保存\n",
    "# with open('boston_scx.pkl','wb') as f:\n",
    "#     pickle.dump(sc_model_x2,f) #xの標準化モデルの保存\n",
    "# with open('boston_scy.pkl','wb') as f:\n",
    "#     pickle.dump(sc_model_y2,f) #yの標準化モデルの保存\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
