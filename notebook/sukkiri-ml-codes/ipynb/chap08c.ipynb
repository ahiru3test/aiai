{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175897572515981 0.7359028880290998\n",
      "0.7190252930186809 0.7295535344941491\n",
      "0.8456207631185566 0.8372526287986777\n",
      "0.8565689444345094 0.8425282632102126\n",
      "0.8643834988984441 0.8678022326740733\n",
      "0.8668534967796697 0.8739347357775972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7649249353669053"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#numeric_only=True\n",
    "\n",
    "class SklModel():\n",
    "    dataframe = None\n",
    "    columns = None\n",
    "    test_parameters = {}\n",
    "    model_parameters = {}\n",
    "\n",
    "    #step 1\n",
    "    @classmethod\n",
    "    def set_filepath(cls, filepath):\n",
    "        cls.filepath = filepath\n",
    "        cls.dataframe = pd.read_csv(filepath) # CSV読込\n",
    "        return cls.dataframe\n",
    "\n",
    "    #step2\n",
    "    @classmethod\n",
    "    def set_parameter(cls, parameters):\n",
    "        cls.model_parameters = parameters\n",
    "\n",
    "    @classmethod\n",
    "    def set_test_parameter(cls, parameters):\n",
    "        cls.test_parameters = parameters\n",
    "\n",
    "    @classmethod\n",
    "    def set_target(cls, target_column):\n",
    "        cls.target_column = target_column\n",
    "\n",
    "        # 特徴量と正解ラベルを分割する\n",
    "        if cls.columns is None:\n",
    "            columns = cls.dataframe.drop(cls.target_column, axis=1).columns.tolist()\n",
    "            cls.set_columns(columns)\n",
    "\n",
    "    @classmethod\n",
    "    def get_target(cls):\n",
    "        return cls.target_column\n",
    "\n",
    "    @classmethod\n",
    "    def set_columns(cls, columns):\n",
    "        cls.columns = columns\n",
    "        return cls.columns\n",
    "        # return cls.columns := columns\n",
    "\n",
    "    @classmethod\n",
    "    def get_columns(cls):\n",
    "        return cls.columns\n",
    "\n",
    "    @classmethod\n",
    "    def split(cls,*parrays):\n",
    "        # データを訓練データとテストデータに分割する\n",
    "        return train_test_split(*parrays, **cls.test_parameters)\n",
    "    \n",
    "    @classmethod\n",
    "    def fillna_meaning(cls, df) -> pd.DataFrame:\n",
    "        return df.fillna(df.mean())\n",
    "\n",
    "    @classmethod\n",
    "    def get_dummy_columns(cls, df:pd.DataFrame, columns:list, drop=0):\n",
    "        drop_flag = {0:False,1:True}\n",
    "        # print(drop_flag[drop])\n",
    "        for column in columns:\n",
    "            dummy = pd.get_dummies(df[column], drop_first=drop_flag[drop], dtype=int)\n",
    "            df = pd.concat([df, dummy], axis=1)\n",
    "        df = df.drop(columns, axis=1)\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def ss_transform(cls, df, model=None):\n",
    "        if (model is None):\n",
    "            sc_model_x = StandardScaler() #訓練データxの標準化モデル\n",
    "            sc_model_x.fit(df)\n",
    "        else:\n",
    "            sc_model_x = model\n",
    "        \n",
    "        # 各列のデータを標準化してsc_xに代入\n",
    "        sc_x = sc_model_x.transform(df) #標準化されたxのdfデータ\n",
    "        sc_x # 表示\n",
    "\n",
    "        return sc_x, sc_model_x\n",
    "    \n",
    "    @classmethod\n",
    "    def init_model(cls,model_name=\"\"):\n",
    "        if(model_name==\"DecisionTreeClassifier\"):\n",
    "            return DecisionTreeClassifier(**cls.model_parameters)\n",
    "        elif(model_name==\"LinearRegression\"):\n",
    "            return LinearRegression()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "#8-1 CSVの読込\n",
    "# import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from DTC2 import DTC\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "df=SklModel.set_filepath(\"../datafiles/Boston.csv\")\n",
    "# print(df.head(2))\n",
    "\n",
    "#8-3 CRIMEの調査\n",
    "df['CRIME'].value_counts()\n",
    "\n",
    "#8-4 ダミー変数設定(自動化候補)\n",
    "df2 = SklModel.get_dummy_columns(df, ['CRIME'], 1)\n",
    "\n",
    "#8-5 columnsの設定が無いのでtarget以外をcolumnsの値とする\n",
    "SklModel.set_test_parameter({\"test_size\": 0.2, \"random_state\": 0})\n",
    "SklModel.dataframe_org = SklModel.dataframe.copy()\n",
    "SklModel.dataframe = df2\n",
    "train_val,test = SklModel.split(df2)\n",
    "train_val,test\n",
    "\n",
    "#8-6 欠損値の処理\n",
    "train_val.isnull().sum()\n",
    "\n",
    "#8-7 欠損値を平均値で穴埋め（自動化候補）\n",
    "train_val2 = SklModel.fillna_meaning(train_val)\n",
    "train_val2\n",
    "\n",
    "#8-8 外れ値の処理（自動化候補）\n",
    "# colname = train_val2.columns\n",
    "# colname\n",
    "# for name in colname[:13]:\n",
    "# for name in colname:\n",
    "#     train_val2.plot(kind = 'scatter', x = name, y = 'PRICE')\n",
    "\n",
    "#8-8-2\n",
    "import matplotlib.pyplot as plt\n",
    "# fig = plt.figure(figsize=(8,10))\n",
    "# colname = train_val2.columns\n",
    "# # for name in colname:   \n",
    "# #     train_val2.plot(kind = 'scatter', x = name, y = 'PRICE')\n",
    "# for n, col in enumerate(colname):\n",
    "#     train_val2.plot(ax=fig.add_subplot(5,3,n+1), kind='scatter', x= col, y='PRICE', s=3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "#8-9 外れ値が存在するインデックスの確認\n",
    "# RMの外れ値\n",
    "out_line1 = train_val2[(train_val2['RM'] < 6) &\n",
    "(train_val2['PRICE'] > 40)].index\n",
    "# PTRATIOの外れ値\n",
    "out_line2 = train_val2[(train_val2['PTRATIO'] > 18) &\n",
    "(train_val2['PRICE'] > 40)].index\n",
    "\n",
    "# print(out_line1, out_line2)\n",
    "\n",
    "#8-10 外れ値の削除\n",
    "train_val3 = train_val2.drop([76], axis = 0)\n",
    "\n",
    "#8-11 予測に使用する特徴量の列以外を取り除く\n",
    "col = ['INDUS', 'NOX', 'RM', 'PTRATIO', 'LSTAT', 'PRICE']\n",
    "\n",
    "train_val4 = train_val3[col]\n",
    "train_val4.head(3)\n",
    "\n",
    "#8-12 各列同士の相関係数を調べる\n",
    "train_val4.corr()\n",
    "\n",
    "#8-13 PRICE列との相関係数を調べる\n",
    "train_cor = train_val4.corr()['PRICE']\n",
    "train_cor\n",
    "\n",
    "#8-16 各要素を絶対値に変換\n",
    "abs_cor = train_cor.map(abs)\n",
    "abs_cor\n",
    "\n",
    "#8-17 降順\n",
    "abs_cor.sort_values(ascending = False)\n",
    "\n",
    "#8-18 データ分割\n",
    "col =SklModel.set_columns(['RM', 'LSTAT', 'PTRATIO'])\n",
    "x = train_val4[col]\n",
    "t = train_val4[['PRICE']]\n",
    "# DTC.set_test_parameter({\"test_size\": 0.2, \"random_state\": 0})\n",
    "\n",
    "x_train, x_val, y_train, y_val = SklModel.split(x,t)\n",
    "x_train, x_val, y_train, y_val\n",
    "\n",
    "#8-19 データ標準化\n",
    "# sc_model_x = StandardScaler() #訓練データxの標準化モデル\n",
    "# sc_model_x.fit(x_train)\n",
    "\n",
    "# # 各列のデータを標準化してsc_xに代入\n",
    "# sc_x = sc_model_x.transform(x_train) #標準化されたxのdfデータ\n",
    "# sc_x # 表示\n",
    "sc_x, sc_model_x = SklModel.ss_transform(x_train)\n",
    "sc_x, sc_model_x\n",
    "\n",
    "#8-20 見やすくして平均値0（ほぼ0）を確認\n",
    "# array 型だと見づらいのでデータフレームに変換\n",
    "tmp_df = pd.DataFrame(sc_x, columns = x_train.columns)\n",
    "# 平均値の計算\n",
    "tmp_df.mean()\n",
    "\n",
    "#8-21 標準偏差の計算\n",
    "tmp_df.std() # 標準偏差の計算\n",
    "\n",
    "#8-22 正解データを標準化\n",
    "sc_y,sc_model_y = SklModel.ss_transform(y_train)\n",
    "\n",
    "###---\n",
    "#決定木\n",
    "# from sklearn import tree\n",
    "# model = tree.DecisionTreeClassifier(max_depth = 3,\n",
    "#     random_state = 0)\n",
    "# model.fit(x_train, y_train)\n",
    "\n",
    "#8-23 標準化したデータで学習\n",
    "model=SklModel.init_model(\"LinearRegression\")\n",
    "model.fit(sc_x,sc_y)\n",
    "\n",
    "#8-24 決定係数を求める\n",
    "model.score(x_val,y_val)\n",
    "\n",
    "#8-25\n",
    "sc_x_val = sc_model_x.transform(x_val)\n",
    "sc_y_val = sc_model_y.transform(y_val)\n",
    "# 標準化した検証データで決定係数を計算\n",
    "model.score(sc_x_val, sc_y_val)\n",
    "\n",
    "#8-27 learn関数\n",
    "def learn(x, t):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, t,\n",
    "    test_size = 0.2, random_state = 0)\n",
    "    # 訓練データを標準化\n",
    "    sc_model_x = StandardScaler()\n",
    "    sc_model_y = StandardScaler()\n",
    "    sc_model_x.fit(x_train)\n",
    "    sc_x_train = sc_model_x.transform(x_train)\n",
    "    sc_model_y.fit(y_train)\n",
    "    sc_y_train = sc_model_y.transform(y_train)\n",
    "    # 学習\n",
    "    model = LinearRegression()\n",
    "    model.fit(sc_x_train, sc_y_train)\n",
    "    #検証データを標準化\n",
    "    sc_x_val = sc_model_x.transform(x_val)\n",
    "    sc_y_val = sc_model_y.transform(y_val)\n",
    "    # 訓練データと検証データの決定係数計算\n",
    "    train_score = model.score(sc_x_train, sc_y_train)\n",
    "    val_score = model.score(sc_x_val, sc_y_val)\n",
    "    return train_score, val_score\n",
    "\n",
    "# 8-28learn関数を実行\n",
    "x = train_val3.loc[ :, ['RM', 'LSTAT', 'PTRATIO']]\n",
    "t = train_val3[['PRICE']]\n",
    "s1,s2 = learn(x, t)\n",
    "print(s1, s2)\n",
    "\n",
    "#8-29 特徴量にINDUS列を追加する\n",
    "x = train_val3.loc[ :, ['RM', 'LSTAT', 'PTRATIO','INDUS']]\n",
    "t = train_val3[['PRICE']]\n",
    "s1,s2 = learn(x, t)\n",
    "print(s1, s2)\n",
    "\n",
    "#8-30特徴量エンジニアリング、RM（部屋数）を２乗する\n",
    "x['RM'] ** 2\n",
    "\n",
    "#8-31 RM2乗列を特徴量に追加する\n",
    "# RM2乗のシリーズを新しい列として追加\n",
    "x['RM2'] = x['RM'] ** 2\n",
    "# コード8-29で、INDUS列を追加したので削除\n",
    "x = x.drop('INDUS', axis = 1)\n",
    "x.head(2)\n",
    "\n",
    "#8-33 再学習\n",
    "s1, s2 = learn(x, t)\n",
    "print(s1, s2)\n",
    "\n",
    "#8-34 LAST列とPTRATIO列の2乗も特徴量に追加\n",
    "# LSTAT列の2乗を追加\n",
    "x['LSTAT2'] = x['LSTAT'] ** 2\n",
    "s1, s2 = learn(x, t)\n",
    "print(s1, s2)\n",
    "\n",
    "# PTRATIO列の2乗を追加\n",
    "x['PTRATIO2'] = x['PTRATIO'] ** 2\n",
    "s1, s2 = learn(x, t)\n",
    "print(s1, s2)\n",
    "\n",
    "#8-35行加算のサンプル\n",
    "se1 = pd.Series([1, 2, 3])\n",
    "se2 = pd.Series([10, 20, 30])\n",
    "se1 + se2 # 対応する各要素を足し算したシリーズ\n",
    "\n",
    "#8-36交互作用特徴量を追加\n",
    "x['RM * LSTAT'] = x['RM'] * x['LSTAT']\n",
    "x.head(2)\n",
    "\n",
    "#8-37 再々学習\n",
    "s1, s2 = learn(x, t)\n",
    "print(s1, s2)\n",
    "\n",
    "#8-38の標準化後に再々学習\n",
    "# 訓練データと検証データを合わせて再学習させるので\n",
    "# 再度、標準化する\n",
    "sc_model_x2 = StandardScaler()\n",
    "sc_model_x2.fit(x)\n",
    "sc_x = sc_model_x2.transform(x)\n",
    "\n",
    "sc_model_y2 = StandardScaler()\n",
    "sc_model_y2.fit(t)\n",
    "sc_y = sc_model_y2.transform(t)\n",
    "model = LinearRegression()\n",
    "model.fit(sc_x, sc_y)\n",
    "\n",
    "#8-38テストデータにも前処理を行う\n",
    "test2 = test.fillna(train_val.mean()) # 欠損値を平均値で補完\n",
    "x_test = test2.loc[ :, ['RM','LSTAT', 'PTRATIO'] ]\n",
    "y_test = test2[['PRICE']]\n",
    "\n",
    "x_test['RM2'] = x_test['RM'] ** 2\n",
    "x_test['LSTAT2'] = x_test['LSTAT'] ** 2\n",
    "x_test['PTRATIO2'] = x_test['PTRATIO'] ** 2\n",
    "\n",
    "x_test['RM * LSTAT'] = x_test['RM'] * x_test['LSTAT']\n",
    "\n",
    "sc_x_test = sc_model_x2.transform(x_test)\n",
    "sc_y_test = sc_model_y2.transform(y_test)\n",
    "\n",
    "#8-40決定係数を計算\n",
    "model.score(sc_x_test, sc_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #8-41モデルの保存\n",
    "# import pickle\n",
    "# with open('boston.pkl',\"wb\") as f:\n",
    "#     pickle.dump(model,f) #モデルの保存\n",
    "# with open('boston_scx.pkl','wb') as f:\n",
    "#     pickle.dump(sc_model_x2,f) #xの標準化モデルの保存\n",
    "# with open('boston_scy.pkl','wb') as f:\n",
    "#     pickle.dump(sc_model_y2,f) #yの標準化モデルの保存\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
